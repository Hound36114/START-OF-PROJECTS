# -*- coding: utf-8 -*-
"""Text_classification_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AiIuyWvhdaF7FsK7riZEisqDWousE3K0
"""

import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_datasets as tfds

train_data, validation_data, test_data = tfds.load(name = 'imdb_reviews',
                                                  split = ('train[:60%]', 'train[60%:]', 'test'),
                                                  as_supervised = True)

def test_data_shapes():
    """Ensure train batches are not empty and labels exist"""
    for batch, label in train_data.batch(10).take(1):
        batch_tensor = tf.convert_to_tensor(batch)
        label_tensor = tf.convert_to_tensor(label)
        assert tf.shape(batch_tensor)[0] > 0
        assert tf.shape(label_tensor)[0] > 0

test_data_shapes()  # Run test immediately

def test_label_values():
    """Check labels are only 0 or 1"""
    # Take a batch of 10 labels to make it a proper tensor
    for _, label in train_data.batch(10).take(1):
        label_tensor = tf.convert_to_tensor(label)      # Ensure it's a proper tensor
        unique_labels = tf.unique(label_tensor)[0].numpy()  # Get unique labels
        assert set(unique_labels).issubset({0, 1})     # Check only 0 or 1

test_label_values()

train_example_batch, train_labels_batch = next(iter(train_data.batch(10)))

train_example_batch

train_labels_batch

class HubWrapper(tf.keras.layers.Layer):
  #Wraps a TensorFlowâ€‘Hub SavedModel so Keras3 sees it as a regular Layer.

  def __init__(self, url: str, trainable: bool = False, **kwargs):
    super().__init__(trainable = trainable, **kwargs)
    self.url = url
    self._hub_model = None #lazy-load in build()

  def build(self, input_shape):
    self._hub_model = hub.load(self.url)
    self._hub_model = tf.function(self._hub_model)
    super().build(input_shape)

  def call(self, inputs):
    outputs = self._hub_model(inputs)

    if isinstance(outputs, dict):
      outputs = outputs.get("default", list(outputs.values())[0])

    return outputs

embedding = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1"
hub_layer = HubWrapper(embedding, dtype = tf.string, trainable = True, name = "text_embedding")

model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(16, activation = 'relu'))
model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))

model.summary()

def test_model_output_range():
    """Ensure model output is in 0-1 range"""
    sample_text = tf.constant(["Amazing movie", "Terrible acting"])
    pred = model(sample_text)
    assert tf.reduce_max(pred) <= 1.0
    assert tf.reduce_min(pred) >= 0.0

test_model_output_range()

model.compile(optimizer = 'adam',
              loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),
              metrics = ['accuracy'])

history = model.fit(train_data.shuffle(10000).batch(100),
                    epochs = 25,
                    validation_data = validation_data.batch(100),
                    verbose = 1)

results = model.evaluate(test_data.batch(100), verbose = 2)

for name, value in zip(model.metrics_names, results):
  print("%s: %.3f" % (name, value))

def test_accuracy_reasonable():
    """Check that model achieves reasonable accuracy on test set"""
    results = model.evaluate(test_data.batch(100), verbose=0)
    accuracy = results[1]
    assert accuracy > 0.5

test_accuracy_reasonable()

import matplotlib.pyplot as plt
def plot_class_distribution():
    pos_count = 0
    neg_count = 0
    for _, label in train_data.take(1000):  # check first 1000 reviews
        if label.numpy() == 1:
            pos_count += 1
        else:
            neg_count += 1

    plt.bar(['Positive', 'Negative'], [pos_count, neg_count], color=['green', 'red'])
    plt.title("Class Distribution in Sample of 1000 Reviews")
    plt.ylabel("Number of Reviews")
    plt.show()



plot_class_distribution()

import matplotlib.pyplot as plt
import seaborn as sns
# Heatmap: Batch-wise Positive/Negative Counts
def plot_class_heatmap(batch_size=100, num_batches=10):
    counts = []

    # Take first `num_batches` batches
    for batch_num, (_, labels) in enumerate(train_data.batch(batch_size).take(num_batches)):
        labels_np = labels.numpy()
        pos = np.sum(labels_np == 1)
        neg = np.sum(labels_np == 0)
        counts.append([pos, neg])

    counts = np.array(counts)  # shape: (num_batches, 2)

    plt.figure(figsize=(6,5))
    sns.heatmap(counts, annot=True, fmt="d", cmap="YlGnBu", xticklabels=['Positive','Negative'], yticklabels=[f'Batch {i+1}' for i in range(num_batches)])
    plt.title("Batch-wise Positive/Negative Review Counts")
    plt.ylabel("Batch Number")
    plt.show()

plot_class_heatmap()